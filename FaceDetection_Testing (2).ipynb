{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S86hQijGcaVQ"
      },
      "outputs": [],
      "source": [
        "#Karam Issa ;)\n",
        "\n",
        "!pip install opencv-python\n",
        "!pip install Pillow\n",
        "# This will download the raw file from the opencv githup repo, to garuantee the file will always be uploaded correctly\n",
        "!wget https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code sets the KAGGLE_CONFIG_DIR environment variable to /content, which is a directory in the Google Colab environment. The KAGGLE_CONFIG_DIR environment variable is used by the Kaggle API client to locate the Kaggle configuration file that contains the user's Kaggle API credentials.\n",
        "\n",
        "By setting the KAGGLE_CONFIG_DIR environment variable to /content, you are telling the Kaggle API client to look for the Kaggle configuration file in the /content directory, which is where you can store the configuration file in the Colab environment. This is necessary for the Kaggle API client to work properly in Colab.\n",
        "\n",
        "\n",
        "**Dont forget to add your kaggle.json api key "
      ],
      "metadata": {
        "id": "O7kI7LJDzswg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#In the context of looping through a folder of images, we can use the os.listdir() function to get a list of all the files in the folder, and then use os.path.join() to construct the full path to each image file. This makes it easy to read and manipulate the images in the folder.\n",
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content'"
      ],
      "metadata": {
        "id": "y0AIbk4-s7Gm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d vin1234/count-the-number-of-faces-present-in-an-image"
      ],
      "metadata": {
        "id": "g_MUS8KJsK9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 /content/kaggle.json"
      ],
      "metadata": {
        "id": "y0WvmIOptOVm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \\*.zip && rm*.zip"
      ],
      "metadata": {
        "id": "WRgYor-athZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries\n",
        "\n",
        "# Used for opening and manipulating image files\n",
        "from PIL import Image\n",
        "\n",
        "# Used for makinf HTTP requests to web servers as the input image if from a URL\n",
        "import requests\n",
        "\n",
        "# Used for working with input and output streams.\n",
        "from io import BytesIO\n",
        "# Opencv Libraray fro image processing and computer vission\n",
        "import cv2\n",
        "\n",
        "# Used here to convert the image to/from a PIL Image object from/to a NumPy array.\n",
        "import numpy as np\n",
        "\n",
        "#The csv module provides classes for reading and writing CSV files, such as csv.reader, csv.writer, csv.DictReader, and csv.DictWriter. These classes provide methods and attributes for working with CSV files, such as iterating over rows, accessing columns by name, writing rows\n",
        "import csv"
      ],
      "metadata": {
        "id": "k68INRw3cgKz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code iterates through each image file in the directory specified by image_path. It attempts to open each image file using the PIL library and skips over any files that cannot be opened. For each valid image file, it converts the image to a NumPy array that can be processed by OpenCV, loads a face detection classifier from a specified file path, and detects faces in the image using the detectMultiScale method. Finally, it writes a new row to the output CSV file with the filename and number of faces detected."
      ],
      "metadata": {
        "id": "AES12Ctg1V_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Set the path to the directory containing the images\n",
        "image_path = '/content/train/image_data/'\n",
        "\n",
        "\n",
        "# Open the output CSV file for writing   \n",
        "with open('output.csv', mode='w') as output_file:\n",
        "\n",
        "  # Create a CSV writer object\n",
        "  csv_writer = csv.writer(output_file)\n",
        "\n",
        "  # Loop through each image file in the directory      \n",
        "  for img in range(10001, 18208):\n",
        "    \n",
        "    # Construct the full path to the image file\n",
        "    image_filename = str(img) + '.jpg'\n",
        "    full_path = image_path + image_filename\n",
        "\n",
        "\n",
        "    # Attempt to open the image file\n",
        "    try:\n",
        "      image = Image.open(full_path)\n",
        "    except:\n",
        "      # If there is an error opening the image file, skip it and move on to the next file\n",
        "      continue\n",
        "    else:\n",
        "      # Convert the image to a NumPy array that can be processed by OpenCv\n",
        "      image_array = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
        "\n",
        "\n",
        "\n",
        "      # Load the face detection classifier from the specified file path\n",
        "      face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "           \n",
        "\n",
        "      # Convert the image to grayscale, which is required for face detection\n",
        "      gray_image = cv2.cvtColor(image_array, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "      # Detect faces in the image using the face detection classifier\n",
        "      faces = face_cascade.detectMultiScale(gray_image, scaleFactor=1.05, minNeighbors=5)\n",
        "\n",
        "      # Write a new row to the output CSV file with the filename and number of faces detected\n",
        "      csv_writer.writerow([image_filename, len(faces)])\n",
        "\n",
        "            \n"
      ],
      "metadata": {
        "id": "cyYlcrhxdDde"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the input file for reading\n",
        "with open('output.csv', 'r') as input_file:\n",
        "    reader = csv.reader(input_file)\n",
        "\n",
        "    # Read in the data rows\n",
        "    data = [row for row in reader]\n",
        "\n",
        "# Insert a new header row at the beginning of the data\n",
        "header_row = ['Name', 'HeadCount']\n",
        "data.insert(0, header_row)\n",
        "\n",
        "# Open the output file for writing\n",
        "with open('output.csv', 'w', newline='') as output_file:\n",
        "    writer = csv.writer(output_file)\n",
        "\n",
        "    # Write out the data to the output file\n",
        "    for row in data:\n",
        "        writer.writerow(row)"
      ],
      "metadata": {
        "id": "1gTm0XRF648U"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code compares the headcount values for each image in the train.csv file with the headcount values obtained from running face detection on the images and stored in the output.csv file.\n",
        "\n",
        "It does this by creating a dictionary headcount_dict that stores the headcount values for each file. It first reads through the train.csv file to get the filename and headcount value for each image. It then reads through the output.csv file to get the headcount value obtained from running face detection on each image. If a match is found between the filename in train.csv and output.csv, the headcount values for both are stored in the headcount_dict dictionary.\n",
        "\n",
        "Finally, the code prints out the headcount values for each file in the headcount_dict dictionary. If a file is not found in the output.csv file, a message is printed indicating that the file was not found."
      ],
      "metadata": {
        "id": "LXduv8V81n2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the train.csv file for reading\n",
        "with open('/content/train/train.csv', 'r') as train_file:\n",
        "    train_reader = csv.DictReader(train_file)\n",
        "\n",
        "    # Open the output.csv file for reading\n",
        "    with open('output.csv', 'r') as output_file:\n",
        "        output_reader = csv.DictReader(output_file)\n",
        "\n",
        "        # Create a dictionary to store the headcount values for each file\n",
        "        headcount_dict = {}\n",
        "\n",
        "        # Iterate over the rows in the train.csv file\n",
        "        for train_row in train_reader:\n",
        "\n",
        "            # Get the filename from the train row\n",
        "            filename = train_row['Name']\n",
        "\n",
        "            # Check if the filename is in the output.csv file\n",
        "            for output_row in output_reader:\n",
        "                if output_row['Name'] == filename:\n",
        "\n",
        "                    # Store the headcount value for this file in the dictionary\n",
        "                    headcount_dict[filename] = {\n",
        "                        'train': int(train_row['HeadCount']),\n",
        "                        'output': int(output_row['HeadCount'])\n",
        "                    }\n",
        "\n",
        "                    # Reset the output reader to the beginning of the file\n",
        "                    output_file.seek(0)\n",
        "                    next(output_reader)\n",
        "\n",
        "                    # Break out of the inner loop since we found a match\n",
        "                    break\n",
        "\n",
        "            # If the filename wasn't found in the output.csv file, print a message\n",
        "            else:\n",
        "                print(f'File {filename} not found in output.csv')\n",
        "\n",
        "# Print the headcount values for each file\n",
        "for filename, counts in headcount_dict.items():\n",
        "    print(f'{filename}: train={counts[\"train\"]}, output={counts[\"output\"]}')"
      ],
      "metadata": {
        "id": "3awEsLDJfoXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare the headcount values for each file\n",
        "same_count = 0\n",
        "for counts in headcount_dict.values():\n",
        "    if counts['train'] == counts['output']:\n",
        "        same_count += 1\n",
        "\n",
        "print(f'{same_count} files had the same train and output headcount values')\n",
        "print(str(same_count/5733 *100)+'% of the files precisely detected correctly')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZtik6n3vF2m",
        "outputId": "8b781265-40ee-442f-dc2c-369c6ccfac81"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1284 files had the same train and output headcount values\n",
            "22.39665096807954% of the files precisely detected correctly\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare the headcount values for each file\n",
        "same_count = 0\n",
        "for counts in headcount_dict.values():\n",
        "    if counts['train'] == counts['output'] or (counts['train'] == counts['output'] +1):\n",
        "        same_count += 1\n",
        "\n",
        "print(f'{same_count} files had output headcount values (-1), one face missing from the train headcount values')\n",
        "print(str(same_count/5733 *100)+'% of the files were partially detected correctly with an possible error of maximum of 1 missing face per image file not detected')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91USWg6sr7zz",
        "outputId": "9b26973c-c89c-4f8e-8e6b-4bec43b560a7"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2594 files had output headcount values (-1), one face missing from the train headcount values\n",
            "45.246816675388104% of the files were partially detected correctly with an possible error of maximum of 1 missing face per image file not detected\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare the headcount values for each file\n",
        "same_count = 0\n",
        "for counts in headcount_dict.values():\n",
        "    if counts['train'] == counts['output'] or (counts['train'] == counts['output'] +1) or (counts['train'] == counts['output'] +2):\n",
        "        same_count += 1\n",
        "\n",
        "print(f'{same_count} files had output headcount values (-1), one face missing from the train headcount values')\n",
        "print(str(same_count/5733 *100)+'% of the files were partially detected correctly with an possible error of  maximum 2 missing face per image file not detected')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7zhvqycu8Us",
        "outputId": "3e3eb3b5-f979-49ed-9c1c-6f578edb2a51"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3489 files had output headcount values (-1), one face missing from the train headcount values\n",
            "60.858189429618% of the files were partially detected correctly with an possible error of  maximum 2 missing face per image file not detected\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create lists of true and predicted headcounts\n",
        "from sklearn.metrics import f1_score\n",
        "y_true = [v['train'] for v in headcount_dict.values()]\n",
        "y_pred = [v['output'] for v in headcount_dict.values()]\n",
        "\n",
        "# Calculate the F1 score\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "# Print the F1 score\n",
        "print(f'The F1 score is: {f1:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bJDezHrsopG",
        "outputId": "21ede586-a841-434a-936d-80c4c8b7c06b"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The F1 score is: 0.24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code block reads data from two CSV files, train.csv and output.csv, and writes the output to a new CSV file named output_with_percentage.csv.\n",
        "\n",
        "The code first creates a dictionary called headcount_dict to store the headcount values for each file. It then iterates over the rows in train.csv, retrieves the filename, and checks if that file exists in output.csv. If it does, the code stores the headcount values for that file in headcount_dict. If it doesn't, the code prints a message indicating that the file was not found.\n",
        "\n",
        "After the data is read from both files and stored in headcount_dict, the code calculates the percentage of faces detected for each file by dividing the output headcount by the train headcount and multiplying by 100. The resulting percentage is then written to a new CSV file called output_with_percentage.csv, along with the other data from output.csv.\n",
        "\n",
        "The csv.DictReader() and csv.DictWriter() functions are used to read and write the CSV files, respectively. The seek() function is used to reset the output file reader to the beginning of the file so that it can be read again for each filename in the train.csv file."
      ],
      "metadata": {
        "id": "A_uIoVvL5PgP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with open('/content/train/train.csv', 'r') as train_file, \\\n",
        "        open('output.csv', 'r') as output_file, \\\n",
        "        open('output_with_percentage.csv', 'w', newline='') as output_with_percentage_file:\n",
        "\n",
        "    train_reader = csv.DictReader(train_file)\n",
        "    output_reader = csv.DictReader(output_file)\n",
        "\n",
        "    # Create a dictionary to store the headcount values for each file\n",
        "    headcount_dict = {}\n",
        "\n",
        "    # Iterate over the rows in the train.csv file\n",
        "    for train_row in train_reader:\n",
        "        # Get the filename from the train row\n",
        "        filename = train_row['Name']\n",
        "\n",
        "        # Check if the filename is in the output.csv file\n",
        "        for output_row in output_reader:\n",
        "            if output_row['Name'] == filename:\n",
        "                # Store the headcount value for this file in the dictionary\n",
        "                headcount_dict[filename] = {\n",
        "                    'train': int(train_row['HeadCount']),\n",
        "                    'output': int(output_row['HeadCount'])\n",
        "                }\n",
        "\n",
        "                # Reset the output reader to the beginning of the file\n",
        "                output_file.seek(0)\n",
        "                next(output_reader)\n",
        "\n",
        "                # Break out of the inner loop since we found a match\n",
        "                break\n",
        "\n",
        "        # If the filename wasn't found in the output.csv file, print a message\n",
        "        else:\n",
        "            print(f'File {filename} not found in output.csv')\n",
        "\n",
        "    # Calculate the percentage of faces detected for each file and write to output_with_percentage.csv\n",
        "    fieldnames = ['Name', 'HeadCount', 'percentageOfFacesDetected']\n",
        "    writer = csv.DictWriter(output_with_percentage_file, fieldnames=fieldnames)\n",
        "    writer.writeheader()\n",
        "\n",
        "    for row in output_reader:\n",
        "        filename = row['Name']\n",
        "        counts = headcount_dict.get(filename)\n",
        "        if counts:\n",
        "            percentage = counts['output'] / counts['train'] * 100\n",
        "            row['percentageOfFacesDetected'] = percentage\n",
        "            writer.writerow(row)\n",
        "\n"
      ],
      "metadata": {
        "id": "lsHyf8r7wxh3"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code block reads data from a CSV file named output_with_percentage.csv and calculates the mean percentage of faces detected across all files in the CSV.\n",
        "\n",
        "The code first opens the CSV file for reading using the with statement and the csv.DictReader() function. It then extracts the values of the percentageOfFacesDetected column from each row of the CSV file and appends them to a list called percentages.\n",
        "\n",
        "After all values have been extracted, the code uses the statistics.mean() function to calculate the mean of the percentages list. The resulting mean is stored in a variable called mean_percentage.\n",
        "\n",
        "Finally, the code prints the mean percentage of faces detected using an f-string that includes the value of mean_percentage."
      ],
      "metadata": {
        "id": "mlpJz2Xs5lNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statistics\n",
        "\n",
        "# Open the output_with_percentage.csv file for reading\n",
        "with open('output_with_percentage.csv', 'r') as output_file:\n",
        "    output_reader = csv.DictReader(output_file)\n",
        "\n",
        "    # Extract the values of the percentageOfFacesDetected column\n",
        "    percentages = []\n",
        "    for row in output_reader:\n",
        "        percentages.append(float(row['percentageOfFacesDetected']))\n",
        "\n",
        "    # Calculate the mean of the percentages\n",
        "    mean_percentage = statistics.mean(percentages)\n",
        "\n",
        "    # Print the mean percentage\n",
        "    print(f\"Mean percentage of faces detected: {mean_percentage}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PQkzCrRyziz",
        "outputId": "f332d8c5-5442-4a6e-9ff9-8d3dc2b3ea54"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean percentage of faces detected: 79.12311646553822\n"
          ]
        }
      ]
    }
  ]
}